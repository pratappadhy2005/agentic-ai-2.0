{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import library\n",
    "from langchain.vectorstores import Pinecone as LangchainPinecone\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's read the document\n",
    "def read_doc(directory):\n",
    "    file_loader = PyPDFDirectoryLoader(directory)\n",
    "    documents = file_loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = read_doc('documents/')\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Divide the docs in chunks\n",
    "\n",
    "def chunk_data(docs, chunk_size=800, chunk_overlap=50):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    docs = text_splitter.split_documents(docs)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = chunk_data(documents)\n",
    "len(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x13b981010>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x13b983710>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key='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', openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Embedding Technique Of OPENAI\n",
    "embeddings = OpenAIEmbeddings(api_key=os.environ['OPENAI_API_KEY'])\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PINECONE_API_KEY\"] = os.getenv(\"PINECONE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vector search db\n",
    "from pinecone import Pinecone\n",
    "pc = Pinecone(\n",
    "    api_key=os.environ[\"PINECONE_API_KEY\"]\n",
    ")\n",
    "index = pc.Index(\"pratap-langchain\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents into Pinecone\n",
    "vectorstore = LangchainPinecone.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "    index_name=\"pratap-langchain\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Cosine Similarity Retreive Results from VectorDB\n",
    "def retrieve_query(query,k=2):\n",
    "    matching_results=vectorstore.similarity_search(query,k=k)\n",
    "    return matching_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain import OpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\",temperature=0.5)\n",
    "chain=load_qa_chain(llm,chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Search answers from VectorDB\n",
    "def retrieve_answers(query):\n",
    "    doc_search=retrieve_query(query)\n",
    "    print(doc_search)\n",
    "    response=chain.run(input_documents=doc_search,question=query)\n",
    "    return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'creationdate': '2023-02-01T05:28:04+05:30', 'creator': 'Adobe Acrobat Pro 10.1.16', 'moddate': '2023-02-01T08:28:21+05:30', 'page': 10.0, 'page_label': '11', 'producer': 'Adobe Acrobat Pro 10.1.16', 'source': 'documents/budget_speech.pdf', 'title': '', 'total_pages': 58.0}, page_content=\"7 \\n \\n \\n \\nfarmers in contributing to the health of fellow citizens by growing these \\n‘Shree Anna’.  \\n22. Now to make India a global hub for ' Shree Anna', the Indian Institute \\nof Millet Research, Hyderabad will be supported as the Centre of Excellence \\nfor sharing best practices, research and technologies at the international \\nlevel.    \\nAgriculture Credit  \\n23. The agriculture credit target will be increased  \\nto ` 20 lakh crore with focus on animal husbandry, dairy and fisheries.  \\nFisheries \\n24. We will launch a new sub-scheme of PM Matsya Sampada Yojana \\nwith targeted investment of ` 6,000 crore to further enable activities of \\nfishermen, fish vendors, and micro & small enterprises, improve value chain \\nefficiencies, and expand the market. \\nCooperation\"), Document(metadata={'creationdate': '2023-02-01T05:28:04+05:30', 'creator': 'Adobe Acrobat Pro 10.1.16', 'moddate': '2023-02-01T08:28:21+05:30', 'page': 10.0, 'page_label': '11', 'producer': 'Adobe Acrobat Pro 10.1.16', 'source': 'documents/budget_speech.pdf', 'title': '', 'total_pages': 58.0}, page_content=\"7 \\n \\n \\n \\nfarmers in contributing to the health of fellow citizens by growing these \\n‘Shree Anna’.  \\n22. Now to make India a global hub for ' Shree Anna', the Indian Institute \\nof Millet Research, Hyderabad will be supported as the Centre of Excellence \\nfor sharing best practices, research and technologies at the international \\nlevel.    \\nAgriculture Credit  \\n23. The agriculture credit target will be increased  \\nto ` 20 lakh crore with focus on animal husbandry, dairy and fisheries.  \\nFisheries \\n24. We will launch a new sub-scheme of PM Matsya Sampada Yojana \\nwith targeted investment of ` 6,000 crore to further enable activities of \\nfishermen, fish vendors, and micro & small enterprises, improve value chain \\nefficiencies, and expand the market. \\nCooperation\")]\n",
      "The agriculture credit target will be increased to 20 lakh crore.\n"
     ]
    }
   ],
   "source": [
    "our_query = \"How much the agriculture target will be increased by how many crore?\"\n",
    "answer = retrieve_answers(our_query)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
